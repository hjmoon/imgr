{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_positive(simi_scores, simi_path_list):\n",
    "    sum_score = 1/np.sum(simi_scores)\n",
    "    probability_distribution = [v*sum_score for v in simi_scores]\n",
    "    pos_filename = np.random.choice(simi_path_list, POSITIVE_MAX_NUM, replace=False, p=probability_distribution)\n",
    "    return pos_filename\n",
    "\n",
    "def find_negative_inner(neg_scores, neg_path_list):\n",
    "    sum_score = 1/np.sum(neg_scores)\n",
    "    probability_distribution = [v*sum_score for v in neg_scores]\n",
    "    neg_filename = np.random.choice(neg_path_list, NEGATIVE_INNER_MAX_NUM, replace=False, p=probability_distribution)\n",
    "    return neg_filename\n",
    "\n",
    "def find_negative_outter(cur_category, category_info):\n",
    "    category_idx_list = [v for v in range(len(category_info))]\n",
    "    random.shuffle(category_idx_list)\n",
    "    keys = category_info.keys()\n",
    "    neg_cat_key = None\n",
    "    for cate_idx in category_idx_list:\n",
    "        k = keys[cate_idx]\n",
    "        if cur_category != category_info[k]:\n",
    "            neg_cat_key = k\n",
    "            break\n",
    "    neg_filelist_path = category_info[neg_cat_key]\n",
    "    \n",
    "    neg_f = open(os.path.join(ROOT_DATA_PATH,neg_filelist_path),'r')\n",
    "    neg_filelist = neg_f.readlines()\n",
    "    neg_f.close()\n",
    "    neg_idx_list = [v for v in range(len(neg_filelist))]\n",
    "    random.shuffle(neg_idx_list)\n",
    "    neg_filename = np.array([neg_filelist[v].split('\\n')[0] for v in neg_idx_list[:NEGATIVE_OUTTER_MAX_NUM]])\n",
    "    return neg_filename\n",
    "\n",
    "def make_triplet_list(anchor, positive, negative):\n",
    "    assert(type(anchor)==str)\n",
    "    assert(type(positive)==np.ndarray)\n",
    "    assert(type(negative)==np.ndarray)\n",
    "#     print(positive.shape)\n",
    "    \n",
    "    positive_inds = [v for v in range(len(positive))]\n",
    "    negative_inds = [v for v in range(len(negative))]\n",
    "    xv1, yv1 = np.meshgrid(positive_inds, negative_inds)\n",
    "#     print(xv1, yv1)\n",
    "    triplet_dataset = []\n",
    "    for i,j in zip(xv1,yv1):\n",
    "        for i_idx, ii in enumerate(i):\n",
    "            triplet_dataset.append([anchor, positive[ii], negative[j[i_idx]]])\n",
    "    return triplet_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debug_visualization(triplet_dataset):\n",
    "    size = len(triplet_dataset)\n",
    "    \n",
    "    for triplet in triplet_dataset:        \n",
    "        gs1 = gridspec.GridSpec(1, 3)\n",
    "        gs1.update(wspace=0.01, hspace=0.02) # set the spacing between axes. \n",
    "        plt.figure(figsize=(3,3))\n",
    "        for im_idx, im_path in enumerate(triplet):\n",
    "            im = cv2.imread(os.path.join('cropped_images','Category-Attribute-Prediction-Benchmark',im_path))\n",
    "            im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            ax1 = plt.subplot(gs1[im_idx])\n",
    "            ax1.set_xticklabels([])\n",
    "            ax1.set_yticklabels([])\n",
    "            ax1.set_aspect('equal')\n",
    "\n",
    "            plt.subplot(1,3,im_idx+1)\n",
    "            if im_idx == 0:\n",
    "                plt.title('anc')\n",
    "            elif im_idx == 1:\n",
    "                plt.title('pos')\n",
    "            else:\n",
    "                plt.title('neg')\n",
    "            plt.imshow(im)\n",
    "            plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "POS_THRESHOLD_SCORE = 0.80\n",
    "NEG_MAX_THRESHOLD_SCORE = 0.6\n",
    "NEG_MIN_THRESHOLD_SCORE = 0.3\n",
    "POSITIVE_MAX_NUM = 8#20\n",
    "NEGATIVE_INNER_MAX_NUM = 4#10\n",
    "NEGATIVE_OUTTER_MAX_NUM = 2#10\n",
    "np.random.seed(222)\n",
    "ROOT_DATA_PATH = 'vectorMatrix'\n",
    "filelist = os.listdir(ROOT_DATA_PATH)\n",
    "category_info = {}\n",
    "for filename in filelist:\n",
    "    if '_filename.txt' in filename:\n",
    "        cate = filename.split('_filename.txt')[0]\n",
    "#     if '_matrix.pkl' in filename:\n",
    "#         cate = filename.split('_matrix.pkl')[0]\n",
    "#         if cate in category_info:\n",
    "#             category_info[cate].append(filename)\n",
    "#         else:\n",
    "        category_info[cate]=filename\n",
    "        \n",
    "fff = open('triplet_dataset_v2_080.txt','w')\n",
    "keys = category_info.keys()\n",
    "# random.shuffle(keys)\n",
    "# keys=keys[:100]\n",
    "for category in keys:\n",
    "#     if category != 'Hoodie_shirt':\n",
    "#         continue\n",
    "#     print('========================================================')\n",
    "#     print(category)\n",
    "#     print('========================================================')\n",
    "    file_order = []\n",
    "    with open(os.path.join('vectorMatrix',category+'_filename.txt'),'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            file_order.append(line.split('\\n')[0])\n",
    "    with open(os.path.join('vectorMatrix',category+'_matrix.pkl'),'rw') as f:\n",
    "        matrix = pickle.load(f)\n",
    "\n",
    "    file_order_inds = [v for v in range(len(file_order))]\n",
    "    \n",
    "#     random.shuffle(file_order_inds)\n",
    "#     file_order_inds = file_order_inds[:5]\n",
    "    \n",
    "    for file_order_ind in file_order_inds:\n",
    "        anchor_filename = file_order[file_order_ind]\n",
    "        scores = matrix[file_order_ind]\n",
    "        \n",
    "        threshold_inds = np.where(np.logical_and(scores <= 0.999999999999, scores > POS_THRESHOLD_SCORE))[0]\n",
    "        simi_scores = scores[threshold_inds]\n",
    "        simi_path_list = [file_order[v] for v in threshold_inds]\n",
    "        \n",
    "        sorted_inds = np.argsort(simi_scores, axis=0)[::-1][:POSITIVE_MAX_NUM]\n",
    "        simi_scores = simi_scores[sorted_inds]\n",
    "        simi_path_list = [simi_path_list[v] for v in sorted_inds]\n",
    "        \n",
    "        size_simi_path_list = len(simi_path_list)\n",
    "        if size_simi_path_list == 0:\n",
    "            continue\n",
    "        \n",
    "        ############\n",
    "        # positive #\n",
    "        ############\n",
    "        if POSITIVE_MAX_NUM < len(simi_scores):\n",
    "            positive_filenames = find_positive(simi_scores, simi_path_list)\n",
    "        else:\n",
    "            positive_filenames = np.array(simi_path_list)\n",
    "        \n",
    "        ##################\n",
    "        # negative inner #\n",
    "        ##################        \n",
    "        threshold_inds = np.where(np.logical_and(scores <= NEG_MAX_THRESHOLD_SCORE, scores > NEG_MIN_THRESHOLD_SCORE))[0]\n",
    "        neg_scores = scores[threshold_inds]\n",
    "        neg_path_list = [file_order[v] for v in threshold_inds]\n",
    "        \n",
    "        sorted_inds = np.argsort(neg_scores, axis=0)[:NEGATIVE_INNER_MAX_NUM]\n",
    "        neg_scores = neg_scores[sorted_inds]\n",
    "        neg_path_list = [neg_path_list[v] for v in sorted_inds]\n",
    "        \n",
    "        if NEGATIVE_INNER_MAX_NUM < len(neg_scores):\n",
    "            negative_inner_filenames = find_negative_inner(neg_scores, neg_path_list)\n",
    "        else:\n",
    "            negative_inner_filenames = np.array(neg_path_list)\n",
    "        \n",
    "        triplet_datase_inner = make_triplet_list(anchor_filename, positive_filenames, negative_inner_filenames)\n",
    "        \n",
    "        ###################\n",
    "        # negative outter #\n",
    "        ###################\n",
    "        negative_outter_filenames = find_negative_outter(category, category_info)\n",
    "        triplet_dataset_outter = make_triplet_list(anchor_filename, positive_filenames, negative_outter_filenames)\n",
    "        \n",
    "        triplet_datase = triplet_datase_inner + triplet_dataset_outter\n",
    "        #debug_visualization(triplet_datase)\n",
    "#         assert(False)\n",
    "        for triplet in triplet_datase:\n",
    "            str_triplet = ''\n",
    "            if len(triplet) != 3:\n",
    "                print(triplet)\n",
    "                assert(False)\n",
    "            for img in triplet:\n",
    "                str_triplet += img + '\\t'\n",
    "                \n",
    "            fff.write(str_triplet[:-1]+'\\n')\n",
    "fff.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
